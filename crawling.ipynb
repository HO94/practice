{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xI6EjGjdMjrm"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uYyhDKqNNrKK"
   },
   "outputs": [],
   "source": [
    "## 선언\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "baseUrl = 'https://www.google.com/?&bih=939&biw=1680&rlz=1C1SQJL_koKR895KR895&hl=ko'\n",
    "\n",
    "save_root = 'downloads'\n",
    "if not os.path.exists(save_root):os.makedirs(save_root)\n",
    "\n",
    "def get_images(query='apple', limit=20):\n",
    "    save_path = os.path.join(save_root, query)\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    # 한글 검색 자동 변환\n",
    "    url = baseUrl + quote_plus(query)\n",
    "    html = urlopen(url)\n",
    "    soup = bs(html, \"html.parser\")\n",
    "    img = soup.find_all(class_='_img', limit=limit)\n",
    "\n",
    "    n = 1\n",
    "    for i in img:\n",
    "        imgUrl = i['data-source']\n",
    "        with urlopen(imgUrl) as f:\n",
    "            with open(os.path.join(save_path, str(n)+'.jpg'),'wb') as h: # w - write b - binary\n",
    "                img = f.read()\n",
    "                h.write(img)\n",
    "        n += 1\n",
    "    print('%s download complete' % (query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bfiYuHYQNxhv"
   },
   "outputs": [],
   "source": [
    "queries =  ['헬멧',\n",
    "            '오토바이',\n",
    "            '얼굴',\n",
    "            ]\n",
    "\n",
    "num_limit = 1100\n",
    "    \n",
    "for query in queries:\n",
    "    get_images(query=query, limit=num_limit)\n",
    "    \n",
    "print('done!!');beep = lambda x: os.system(\"echo -n '\\a';sleep 0.3;\" * x);beep(3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HhEph5tI8V--"
   },
   "outputs": [],
   "source": [
    "!pip install Selenium\n",
    "!apt-get update # to update ubuntu to correctly run apt install\n",
    "!apt install chromium-chromedriver\n",
    "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
    "import sys\n",
    "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
    "from selenium import webdriver\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
    "wd.get(\"https://www.webite-url.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8uRcMYlUc5bc"
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import json\n",
    "import os\n",
    "\n",
    "class ImageCrawler(object):\n",
    "    def __init__(self, search_term, num_to_search, out_dir):\n",
    "        url = \"https://www.google.co.in/search?q=\" + search_term + \"&tbm=isch\"\n",
    "        browser = webdriver.Chrome(\"chromedriver.exe\")\n",
    "        browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MdSitJ5xc9iz"
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
    "search_term = '헬멧'\n",
    "url = \"https://www.google.co.in/search?q=\" + search_term + \"&tbm=isch\"\n",
    "wd.get(url)\n",
    "\n",
    "for i in range(200):\n",
    "    wd.execute_script('window.scrollBy(0,10000)')\n",
    "\n",
    "for idx, el in enumerate(wd.find_elements_by_class_name(\"rg_ic\")):\n",
    "    el.screenshot(str(idx) + \".png\")\n",
    "\n",
    "\n",
    "first_list = ['헬멧', '얼굴', '사람얼굴']\n",
    "second_list = ['오토바이', '오토바이탄사람', '정면얼굴', '측면', '오토바이사진']\n",
    "\n",
    "for first in first_list:\n",
    "    for second in second_list:\n",
    "        new_query = first + \" \" + second\n",
    "        url = \"https://www.google.co.in/search?q=\" + new_query + \"&tbm=isch\"\n",
    "        wd.get(url)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fqFOqlAiET_m"
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import requests as req\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from urllib.request import urlopen\n",
    "\n",
    "#브라우저를 크롬으로 만들어주고 인스턴스를 생성해준다.\n",
    "browser = wd \n",
    "#브라우저를 오픈할 때 시간간격을 준다.\n",
    "browser.implicitly_wait(3)\n",
    "\n",
    "count = 0\n",
    "검색어 = '헬멧'\n",
    "\n",
    "photo_list = []\n",
    "before_src=\"\"\n",
    "\n",
    "#개요에서 설명했다시피 google이 아니라 naver에서 긁어왔으며, \n",
    "#추가적으로 나는 1027x760이상의 고화질의 해상도가 필요해서 아래와 같이 추가적인 옵션이 달려있다.\n",
    "경로 = \"https://search.naver.com/search.naver?where=image&section=image&query=\"+검색어+\"&res_fr=786432&res_to=100000000&sm=tab_opt&face=0&color=0&ccl=0&nso=so%3Ar%2Ca%3Aall%2Cp%3Aall&datetype=0&startdate=0&enddate=0&start=1\"\n",
    "\n",
    "#해당 경로로 브라우져를 오픈해준다.\n",
    "browser.get(경로)\n",
    "time.sleep(1)\n",
    "\n",
    "SCROLL_PAUSE_TIME = 1.0\n",
    "reallink = []\n",
    "\n",
    "while True:\n",
    "    pageString = browser.page_source\n",
    "    bsObj = BeautifulSoup(pageString, 'lxml')\n",
    "\n",
    "    for link1 in bsObj.find_all(name='div', attrs={\"class\":\"Nnq7C weEfm\"}):\n",
    "        for i in range(3):\n",
    "            title = link1.select('a')[i]\n",
    "            real = title.attrs['href']\n",
    "            reallink.append(real)\n",
    "\n",
    "    last_height = browser.execute_script('return document.body.scrollHeight')\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if new_height == last_height:\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        else:\n",
    "            last_height = new_height\n",
    "            continue\n",
    "\n",
    "#아래 태그의 출처는 사진에서 나오는 출처를 사용한것이다.\n",
    "#여기서 주의할 점은 find_element가 아니라 elements를 사용해서 아래 span태그의 img_border클래스를 \n",
    "#모두 가져왔다.\n",
    "photo_list = browser.find_elements_by_tag_name(\"span.img_border\")\n",
    "\n",
    "\n",
    "for index, img in enumerate(photo_list[0:]):\n",
    "    #위의 큰 이미지를 구하기 위해 위의 태그의 리스트를 하나씩 클릭한다.\n",
    "    img.click()\n",
    "    \n",
    "    #한번에 많은 접속을 하여 image를 크롤링하게 되면 naver, google서버에서 우리의 IP를 10~20분\n",
    "    #정도 차단을 하게된다. 때문에 Crawling하는 간격을 주어 IP 차단을 피하도록 장치를 넣어주었다.\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #확대된 이미지의 정보는 img태그의 _image_source라는 class안에 담겨있다.\n",
    "    html_objects = browser.find_element_by_tag_name('img._image_source')\n",
    "    current_src = html_objects.get_attribute('src')\n",
    "    print(\"=============================================================\")\n",
    "    print(\"현재 src :\" +current_src)\n",
    "    print(\"이전 src :\" +before_src)\n",
    "    if before_src == current_src:  \n",
    "        continue\n",
    "    elif before_src != current_src:\n",
    "        t = urlopen(current_src).read()\n",
    "        if index < 1000 :\n",
    "            filename = \"Car_\"+str(count)+\".jpg\"\n",
    "            with open(filename, \"wb\") as f:\n",
    "                f.write(t)\n",
    "                count += 1\n",
    "                before_src = current_src\n",
    "                current_src = \"\"\n",
    "            print(\"Img Save Success\")\n",
    "        else:\n",
    "            browser.close()       \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fAstAQXraojG"
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import json\n",
    "import os\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3378,
     "status": "ok",
     "timestamp": 1597332488534,
     "user": {
      "displayName": "심병창",
      "photoUrl": "",
      "userId": "14479426968163659486"
     },
     "user_tz": -540
    },
    "id": "ZzWsLagQbwwh",
    "outputId": "ad5cd0ce-364e-42cc-be87-6527f2cdacdf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: use options instead of chrome_options\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "browser = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
    "browser.get('https://www.google.com')\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3CY_CE-2i6J7"
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from urllib.request import urlretrieve\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "os.chdir(\"/content/drive/My Drive/smartcity_project\")\n",
    "def get_images(keyword):\n",
    "\n",
    "    print(\"접속중\")\n",
    "    driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "    url='https://search.naver.com/search.naver?sm=tab_hty.top&where=image&query={}'.format(keyword)\n",
    "    driver.get(url)\n",
    "\n",
    "    \n",
    "    body=driver.find_element_by_css_selector('body')\n",
    "    \n",
    "    num_of_pagedwons=10\n",
    "\n",
    "    while num_of_pagedwons:\n",
    "      body.send_keys(Keys.PAGE_DOWN)\n",
    "      time.sleep(1)\n",
    "      num_of_pagedwons -= 1\n",
    "      try:\n",
    "        driver.find_element_by_xpath(\"\"\"//*[@id=\"btn_more _more\"]/tCR\"\"\").click()\n",
    "      except:\n",
    "        None\n",
    "\n",
    "\n",
    "    #이미지 링크 수집\n",
    "    imgs= driver.find_elements_by_css_selector(\"img._img\")\n",
    "    result=[]\n",
    "    for img in tqdm(imgs):\n",
    "        if 'http' in img.get_attribute('src'):\n",
    "            result.append(img.get_attribute('src'))\n",
    "\n",
    "    driver.close() # 크롬창 자동 종료\n",
    "    print(\"수집 완료\")\n",
    "\n",
    "    #폴더생성\n",
    "    print(\"폴더 생성\")\n",
    "    #폴더가 없을때만 생성\n",
    "    if not os.path.isdir('./{}'.format(keyword)):\n",
    "        os.mkdir('./{}'.format(keyword))\n",
    "\n",
    "    #다운로드\n",
    "    for index, link in tqdm(enumerate(result)): #tqdm은 작업현황을 알려줌.\n",
    "        start=link.rfind('.') #뒤쪽부터 검사\n",
    "        end=link.rfind('&')\n",
    "        filetype=link[start:end] # .jpg , .png 같은게 뽑힘\n",
    "\n",
    "        urlretrieve(link,'./{}/{}{}{}'.format(keyword,keyword,index,filetype))\n",
    "\n",
    "    print('다운로드 완료')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    keyword=input(\"수집할 키워드를 입력하세요: \")\n",
    "    get_images(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AFGSHPSz94xu"
   },
   "outputs": [],
   "source": [
    "def crawling():\n",
    "    global crawled_count\n",
    "\n",
    "    print(\"ㅡ 크롤링 시작 ㅡ\")\n",
    "\n",
    "    # 이미지 고급검색 중 이미지 유형 '사진'\n",
    "    url = f\"https://www.google.com/search?as_st=y&tbm=isch&hl=ko&as_q={query}&as_epq=&as_oq=&as_eq=&cr=&as_sitesearch=&safe=images&tbs=itp:photo\"\n",
    "    driver.get(url)\n",
    "    driver.maximize_window()\n",
    "    scroll_down()\n",
    "\n",
    "    div = driver.find_element_by_xpath('//*[@id=\"islrg\"]/div[1]')\n",
    "    img_list = div.find_elements_by_css_selector(\".rg_i.Q4LuWd\")\n",
    "    os.makedirs(path + date + '/' + query)\n",
    "    print(f\"ㅡ {path}{date}/{query} 생성 ㅡ\")\n",
    "\n",
    "    for index, img in enumerate(img_list):\n",
    "        try:\n",
    "            click_and_retrieve(index, img, len(img_list))\n",
    "\n",
    "        except ElementClickInterceptedException:\n",
    "            print(\"ㅡ ElementClickInterceptedException ㅡ\")\n",
    "            driver.execute_script(\"window.scrollTo(0, window.scrollY + 100)\")\n",
    "            print(\"ㅡ 100만큼 스크롤 다운 및 3초 슬립 ㅡ\")\n",
    "            time.sleep(3)\n",
    "            click_and_retrieve(index, img, len(img_list))\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            print(\"ㅡ NoSuchElementException ㅡ\")\n",
    "            driver.execute_script(\"window.scrollTo(0, window.scrollY + 100)\")\n",
    "            print(\"ㅡ 100만큼 스크롤 다운 및 3초 슬립 ㅡ\")\n",
    "            time.sleep(3)\n",
    "            click_and_retrieve(index, img, len(img_list))\n",
    "\n",
    "        except ConnectionResetError:\n",
    "            print(\"ㅡ ConnectionResetError & 패스 ㅡ\")\n",
    "            pass\n",
    "\n",
    "        except URLError:\n",
    "            print(\"ㅡ URLError & 패스 ㅡ\")\n",
    "            pass\n",
    "\n",
    "        except socket.timeout:\n",
    "            print(\"ㅡ socket.timeout & 패스 ㅡ\")\n",
    "            pass\n",
    "\n",
    "        except socket.gaierror:\n",
    "            print(\"ㅡ socket.gaierror & 패스 ㅡ\")\n",
    "            pass\n",
    "\n",
    "        except ElementNotInteractableException:\n",
    "            print(\"ㅡ ElementNotInteractableException ㅡ\")\n",
    "            break\n",
    "\n",
    "    try:\n",
    "        print(\"ㅡ 크롤링 종료 (성공률: %.2f%%) ㅡ\" % (crawled_count / len(img_list) * 100.0))\n",
    "\n",
    "    except ZeroDivisionError:\n",
    "        print(\"ㅡ img_list 가 비어있음 ㅡ\")\n",
    "\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BUpvaNXT9-Sq"
   },
   "outputs": [],
   "source": [
    "def filtering():\n",
    "    print(\"ㅡ 필터링 시작 ㅡ\")\n",
    "    filtered_count = 0\n",
    "    dir_name = path + date + '/' + query\n",
    "    for index, file_name in enumerate(os.listdir(dir_name)):\n",
    "        try:\n",
    "            file_path = os.path.join(dir_name, file_name)\n",
    "            img = Image.open(file_path)\n",
    "\n",
    "            # 이미지 해상도의 가로와 세로가 모두 350이하인 경우\n",
    "            if img.width < 351 and img.height < 351:\n",
    "                img.close()\n",
    "                os.remove(file_path)\n",
    "                print(f\"{index} 번째 사진 삭제\")\n",
    "                filtered_count += 1\n",
    "\n",
    "        # 이미지 파일이 깨져있는 경우\n",
    "        except OSError:\n",
    "            os.remove(file_path)\n",
    "            filtered_count += 1\n",
    "\n",
    "    print(f\"ㅡ 필터링 종료 (총 갯수: {crawled_count - filtered_count}) ㅡ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "10gtJoQq9-0-"
   },
   "outputs": [],
   "source": [
    "def checking():\n",
    "    # 입력 받은 검색어가 이름인 폴더가 존재하면 중복으로 판단\n",
    "    for dir_name in os.listdir(path):\n",
    "        file_list = os.listdir(path + dir_name)\n",
    "        if query in file_list:\n",
    "            print(f\"ㅡ 중복된 검색어 ({dir_name}) ㅡ\")\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K4gF40x_-AFU"
   },
   "outputs": [],
   "source": [
    "def playing_mp3():\n",
    "    mp3 = \"Mococo_Seed.mp3\"\n",
    "    mixer.init()\n",
    "    mixer.music.load(mp3)\n",
    "    mixer.music.play()\n",
    "    while mixer.music.get_busy():\n",
    "        pass\n",
    "    print(f\"ㅡ 검색어: {query} ㅡ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 941,
     "status": "error",
     "timestamp": 1597408952306,
     "user": {
      "displayName": "심병창",
      "photoUrl": "",
      "userId": "14479426968163659486"
     },
     "user_tz": -540
    },
    "id": "-qZ4NfPz-A4T",
    "outputId": "4bad0be1-2783-4c8c-df9b-2c3273835908"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f3b698f744de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# clickAndRetrieve() 과정에서 urlretrieve 이 너무 오래 걸릴 경우를 대비해 타임 아웃 지정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefaulttimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 이미지들이 저장될 경로 및 폴더 이름\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"C:/Data/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'socket' is not defined"
     ]
    }
   ],
   "source": [
    "# clickAndRetrieve() 과정에서 urlretrieve 이 너무 오래 걸릴 경우를 대비해 타임 아웃 지정\n",
    "socket.setdefaulttimeout(30)\n",
    "\n",
    "# 이미지들이 저장될 경로 및 폴더 이름\n",
    "path = \"C:/Data/\"\n",
    "date = \"2020.07.17\"\n",
    "\n",
    "# 드라이버 경로 지정 (Microsoft Edge)\n",
    "driver = webdriver.Edge(\"C:/Users/user/msedgedriver\")\n",
    "\n",
    "# 크롤링한 이미지 수\n",
    "crawled_count = 0\n",
    "\n",
    "# 검색어 입력 받기\n",
    "query = input(\"입력: \")\n",
    "# 이미 크롤링했던 검색어일 때\n",
    "while checking() is True:\n",
    "    query = input(\"입력: \")\n",
    "\n",
    "crawling()\n",
    "filtering()\n",
    "playing_mp3()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "crawling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
